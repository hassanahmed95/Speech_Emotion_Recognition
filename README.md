# Speech_Emotion_Recognition
Speech Emotion Recognition System aims to automatically identify the emotional state of human being from his or her
voice. It is based on in-depth analysis of generation mechanism of speech signal, extracting some features which contain
emotional information (like happy, angry and sad) from the speaker voice. In that project a neural network has been
trained on normalize data using Keras (deep learning library), in order to classify speech signal.
In the training of the model, to make predictions on the unseen samples the MFCC features has been extracted from the trainning
data and these features has been resmapling by using padding in order to equalize their lengths.
